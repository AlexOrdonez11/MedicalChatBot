{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2cc8a5-ce9f-4e33-b814-dec80cc2eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bd136201-5c9e-4141-bfb1-296210b84553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ale11\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Conversation\n",
       "214  The conversation between human and AI assistan...\n",
       "215  The conversation between human and AI assistan...\n",
       "216  The conversation between human and AI assistan...\n",
       "217  The conversation between human and AI assistan...\n",
       "218  The conversation between human and AI assistan...\n",
       "..                                                 ...\n",
       "316  The conversation between human and AI assistan...\n",
       "317  The conversation between human and AI assistan...\n",
       "318  The conversation between human and AI assistan...\n",
       "319  The conversation between human and AI assistan...\n",
       "320  The conversation between human and AI assistan...\n",
       "\n",
       "[107 rows x 1 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read Dataset and Cleanin Process\n",
    "df = pd.read_csv(r\"train.csv\")\n",
    "df = np.array_split(df,1000)[2]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bd8fb56b-f473-4a57-9fbd-d70eb4b3243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Conversation1']=df['Conversation'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b82d853d-cd80-4c06-a25f-91a9e6f5f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Conversation1']=df['Conversation1'].str.replace('The conversation between human and AI assistant.[|Human|] ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "04239dad-483e-4b9b-8f89-01d8302414ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Human']=\"User: \"+df['Conversation1'].str.split(\"\\[\\|AI\\|\\]\",expand=True)[0]\n",
    "df['AI']=\"ChatBot: \"+df['Conversation1'].str.split(\"\\[\\|AI\\|\\]\",expand=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6be8c6af-ca09-4137-8660-be45054a3e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Whole']= df['Conversation1'].str.replace('[|AI|]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "626fd4da-2241-4757-8cbc-bb1e80a1acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df['Whole']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c689411a-efb1-4d18-85d3-40ab74a1d031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ale11\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#tokenize the model\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98a98c69-f8d3-4152-ab5e-5f24e2778704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Structure for DataLoader of Torch\n",
    "class ChatDataset(Dataset):\n",
    "    def __init__(self, input_encodings, target_encodings):\n",
    "        self.input_encodings = input_encodings\n",
    "        self.target_encodings = target_encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_encodings['input_ids'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.input_encodings['input_ids'][idx]\n",
    "        attention_mask = self.input_encodings['attention_mask'][idx]\n",
    "        labels = self.target_encodings['input_ids'][idx]\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b8ff877a-fe1b-45eb-8e41-116c43fecfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the inputs and labels Create dataset and dataloader\n",
    "\n",
    "input_encodings = tokenizer(list(df['Human']), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "target_encodings = tokenizer(list(df['AI']), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "dataset = ChatDataset(input_encodings, target_encodings)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4e7fe4c3-dc11-4b9c-9b85-8e207b89e7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ale11\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.8559985160827637\n",
      "Epoch 0, Loss: 1.4361222982406616\n",
      "Epoch 0, Loss: 0.751570999622345\n",
      "Epoch 0, Loss: 1.0553346872329712\n",
      "Epoch 0, Loss: 1.6190959215164185\n",
      "Epoch 0, Loss: 0.8255897164344788\n",
      "Epoch 0, Loss: 0.9983565211296082\n",
      "Epoch 0, Loss: 1.1314153671264648\n",
      "Epoch 0, Loss: 1.5597975254058838\n",
      "Epoch 0, Loss: 0.789936900138855\n",
      "Epoch 0, Loss: 0.8923855423927307\n",
      "Epoch 0, Loss: 2.143014430999756\n",
      "Epoch 0, Loss: 0.9085750579833984\n",
      "Epoch 0, Loss: 1.1713602542877197\n",
      "Epoch 0, Loss: 1.2147481441497803\n",
      "Epoch 0, Loss: 1.0133049488067627\n",
      "Epoch 0, Loss: 1.1518000364303589\n",
      "Epoch 0, Loss: 0.9206996560096741\n",
      "Epoch 0, Loss: 0.828273355960846\n",
      "Epoch 0, Loss: 1.0379703044891357\n",
      "Epoch 0, Loss: 1.5836138725280762\n",
      "Epoch 0, Loss: 1.686095118522644\n",
      "Epoch 0, Loss: 1.3690797090530396\n",
      "Epoch 0, Loss: 0.5834330320358276\n",
      "Epoch 0, Loss: 1.1401267051696777\n",
      "Epoch 0, Loss: 0.8470251560211182\n",
      "Epoch 0, Loss: 1.451306939125061\n",
      "Epoch 0, Loss: 1.1547185182571411\n",
      "Epoch 0, Loss: 1.5060133934020996\n",
      "Epoch 0, Loss: 2.8503077030181885\n",
      "Epoch 0, Loss: 0.9094547033309937\n",
      "Epoch 0, Loss: 1.441542387008667\n",
      "Epoch 0, Loss: 1.0101317167282104\n",
      "Epoch 0, Loss: 0.940830647945404\n",
      "Epoch 0, Loss: 0.7865893840789795\n",
      "Epoch 0, Loss: 0.8022270798683167\n",
      "Epoch 0, Loss: 1.5516619682312012\n",
      "Epoch 0, Loss: 1.0131157636642456\n",
      "Epoch 0, Loss: 1.1046650409698486\n",
      "Epoch 0, Loss: 0.865946888923645\n",
      "Epoch 0, Loss: 0.9778808951377869\n",
      "Epoch 0, Loss: 1.074121117591858\n",
      "Epoch 0, Loss: 1.8805596828460693\n",
      "Epoch 0, Loss: 1.2147064208984375\n",
      "Epoch 0, Loss: 0.8134673237800598\n",
      "Epoch 0, Loss: 1.3178287744522095\n",
      "Epoch 0, Loss: 1.1971423625946045\n",
      "Epoch 0, Loss: 0.9904956221580505\n",
      "Epoch 0, Loss: 1.24202299118042\n",
      "Epoch 0, Loss: 0.9905311465263367\n",
      "Epoch 0, Loss: 1.2322088479995728\n",
      "Epoch 0, Loss: 1.0696710348129272\n",
      "Epoch 0, Loss: 0.6828039288520813\n",
      "Epoch 0, Loss: 0.8386388421058655\n",
      "Epoch 1, Loss: 0.8765917420387268\n",
      "Epoch 1, Loss: 1.335923433303833\n",
      "Epoch 1, Loss: 0.896984338760376\n",
      "Epoch 1, Loss: 0.7125896215438843\n",
      "Epoch 1, Loss: 1.470091700553894\n",
      "Epoch 1, Loss: 1.3299860954284668\n",
      "Epoch 1, Loss: 1.8421272039413452\n",
      "Epoch 1, Loss: 0.8643614053726196\n",
      "Epoch 1, Loss: 0.9414811134338379\n",
      "Epoch 1, Loss: 1.1007955074310303\n",
      "Epoch 1, Loss: 0.9900217056274414\n",
      "Epoch 1, Loss: 1.2475544214248657\n",
      "Epoch 1, Loss: 1.4213871955871582\n",
      "Epoch 1, Loss: 0.8899387121200562\n",
      "Epoch 1, Loss: 0.868398904800415\n",
      "Epoch 1, Loss: 1.0895308256149292\n",
      "Epoch 1, Loss: 0.8778892159461975\n",
      "Epoch 1, Loss: 1.0528123378753662\n",
      "Epoch 1, Loss: 1.0471686124801636\n",
      "Epoch 1, Loss: 0.9692062735557556\n",
      "Epoch 1, Loss: 1.2810744047164917\n",
      "Epoch 1, Loss: 0.6378360986709595\n",
      "Epoch 1, Loss: 0.9197794795036316\n",
      "Epoch 1, Loss: 1.5406160354614258\n",
      "Epoch 1, Loss: 0.921491265296936\n",
      "Epoch 1, Loss: 1.1210967302322388\n",
      "Epoch 1, Loss: 1.3472731113433838\n",
      "Epoch 1, Loss: 1.1965070962905884\n",
      "Epoch 1, Loss: 0.92366623878479\n",
      "Epoch 1, Loss: 2.575792074203491\n",
      "Epoch 1, Loss: 1.0411458015441895\n",
      "Epoch 1, Loss: 1.3225212097167969\n",
      "Epoch 1, Loss: 0.7060630321502686\n",
      "Epoch 1, Loss: 0.8311251401901245\n",
      "Epoch 1, Loss: 1.349910020828247\n",
      "Epoch 1, Loss: 0.911812424659729\n",
      "Epoch 1, Loss: 0.840660572052002\n",
      "Epoch 1, Loss: 0.7169991135597229\n",
      "Epoch 1, Loss: 1.0973600149154663\n",
      "Epoch 1, Loss: 1.1026670932769775\n",
      "Epoch 1, Loss: 1.4830105304718018\n",
      "Epoch 1, Loss: 0.7961610555648804\n",
      "Epoch 1, Loss: 0.9455681443214417\n",
      "Epoch 1, Loss: 1.3669326305389404\n",
      "Epoch 1, Loss: 0.6704336404800415\n",
      "Epoch 1, Loss: 1.0470775365829468\n",
      "Epoch 1, Loss: 1.2656359672546387\n",
      "Epoch 1, Loss: 1.1977522373199463\n",
      "Epoch 1, Loss: 1.2156163454055786\n",
      "Epoch 1, Loss: 0.8096782565116882\n",
      "Epoch 1, Loss: 1.4530524015426636\n",
      "Epoch 1, Loss: 0.9936224222183228\n",
      "Epoch 1, Loss: 1.317979335784912\n",
      "Epoch 1, Loss: 1.2251949310302734\n",
      "Epoch 2, Loss: 0.8675892949104309\n",
      "Epoch 2, Loss: 1.70551335811615\n",
      "Epoch 2, Loss: 1.429047703742981\n",
      "Epoch 2, Loss: 0.6820594072341919\n",
      "Epoch 2, Loss: 0.8559202551841736\n",
      "Epoch 2, Loss: 0.8623215556144714\n",
      "Epoch 2, Loss: 0.6306224465370178\n",
      "Epoch 2, Loss: 1.1069022417068481\n",
      "Epoch 2, Loss: 1.2969069480895996\n",
      "Epoch 2, Loss: 0.866027295589447\n",
      "Epoch 2, Loss: 1.055654525756836\n",
      "Epoch 2, Loss: 0.9498250484466553\n",
      "Epoch 2, Loss: 0.9435919523239136\n",
      "Epoch 2, Loss: 1.2305902242660522\n",
      "Epoch 2, Loss: 1.097237229347229\n",
      "Epoch 2, Loss: 1.0305122137069702\n",
      "Epoch 2, Loss: 0.8545249700546265\n",
      "Epoch 2, Loss: 1.9445675611495972\n",
      "Epoch 2, Loss: 0.8082571625709534\n",
      "Epoch 2, Loss: 1.0732218027114868\n",
      "Epoch 2, Loss: 1.0629444122314453\n",
      "Epoch 2, Loss: 1.0897377729415894\n",
      "Epoch 2, Loss: 0.9753472805023193\n",
      "Epoch 2, Loss: 1.1789239645004272\n",
      "Epoch 2, Loss: 1.9552901983261108\n",
      "Epoch 2, Loss: 0.6531859040260315\n",
      "Epoch 2, Loss: 0.9692949652671814\n",
      "Epoch 2, Loss: 1.0692895650863647\n",
      "Epoch 2, Loss: 0.8517000675201416\n",
      "Epoch 2, Loss: 1.5373854637145996\n",
      "Epoch 2, Loss: 0.8725814819335938\n",
      "Epoch 2, Loss: 0.6851529479026794\n",
      "Epoch 2, Loss: 1.0043079853057861\n",
      "Epoch 2, Loss: 1.519026517868042\n",
      "Epoch 2, Loss: 1.530407428741455\n",
      "Epoch 2, Loss: 0.9670731425285339\n",
      "Epoch 2, Loss: 2.466308355331421\n",
      "Epoch 2, Loss: 0.8159725666046143\n",
      "Epoch 2, Loss: 0.8052784204483032\n",
      "Epoch 2, Loss: 1.0833735466003418\n",
      "Epoch 2, Loss: 0.8582711219787598\n",
      "Epoch 2, Loss: 1.108561396598816\n",
      "Epoch 2, Loss: 1.306671380996704\n",
      "Epoch 2, Loss: 0.8444182872772217\n",
      "Epoch 2, Loss: 0.6478323936462402\n",
      "Epoch 2, Loss: 1.3016350269317627\n",
      "Epoch 2, Loss: 0.816125750541687\n",
      "Epoch 2, Loss: 0.9834409952163696\n",
      "Epoch 2, Loss: 1.2750351428985596\n",
      "Epoch 2, Loss: 1.5195900201797485\n",
      "Epoch 2, Loss: 1.1781665086746216\n",
      "Epoch 2, Loss: 0.8954575061798096\n",
      "Epoch 2, Loss: 0.7340235710144043\n",
      "Epoch 2, Loss: 1.1626893281936646\n",
      "Epoch 3, Loss: 0.6489152312278748\n",
      "Epoch 3, Loss: 1.7150508165359497\n",
      "Epoch 3, Loss: 1.2963626384735107\n",
      "Epoch 3, Loss: 0.998925507068634\n",
      "Epoch 3, Loss: 1.0866456031799316\n",
      "Epoch 3, Loss: 1.421547770500183\n",
      "Epoch 3, Loss: 1.2227174043655396\n",
      "Epoch 3, Loss: 1.1159521341323853\n",
      "Epoch 3, Loss: 0.8063141703605652\n",
      "Epoch 3, Loss: 1.3169811964035034\n",
      "Epoch 3, Loss: 0.9254777431488037\n",
      "Epoch 3, Loss: 0.8189836144447327\n",
      "Epoch 3, Loss: 0.7511109709739685\n",
      "Epoch 3, Loss: 1.0739405155181885\n",
      "Epoch 3, Loss: 0.757908046245575\n",
      "Epoch 3, Loss: 1.3329124450683594\n",
      "Epoch 3, Loss: 0.9087010622024536\n",
      "Epoch 3, Loss: 1.0051738023757935\n",
      "Epoch 3, Loss: 1.6671102046966553\n",
      "Epoch 3, Loss: 1.2651548385620117\n",
      "Epoch 3, Loss: 0.7731543183326721\n",
      "Epoch 3, Loss: 1.079125165939331\n",
      "Epoch 3, Loss: 0.9113488793373108\n",
      "Epoch 3, Loss: 0.8267090916633606\n",
      "Epoch 3, Loss: 2.998349189758301\n",
      "Epoch 3, Loss: 0.9199926853179932\n",
      "Epoch 3, Loss: 1.3973771333694458\n",
      "Epoch 3, Loss: 1.0349066257476807\n",
      "Epoch 3, Loss: 0.9819259643554688\n",
      "Epoch 3, Loss: 1.1394755840301514\n",
      "Epoch 3, Loss: 0.8112112283706665\n",
      "Epoch 3, Loss: 1.096564769744873\n",
      "Epoch 3, Loss: 0.7555335164070129\n",
      "Epoch 3, Loss: 0.8087826371192932\n",
      "Epoch 3, Loss: 0.868945837020874\n",
      "Epoch 3, Loss: 0.8231381177902222\n",
      "Epoch 3, Loss: 0.7514704465866089\n",
      "Epoch 3, Loss: 1.0103092193603516\n",
      "Epoch 3, Loss: 0.8233462572097778\n",
      "Epoch 3, Loss: 0.9992426037788391\n",
      "Epoch 3, Loss: 1.1703968048095703\n",
      "Epoch 3, Loss: 0.9945382475852966\n",
      "Epoch 3, Loss: 1.7186248302459717\n",
      "Epoch 3, Loss: 2.0376646518707275\n",
      "Epoch 3, Loss: 0.8426734805107117\n",
      "Epoch 3, Loss: 0.56708824634552\n",
      "Epoch 3, Loss: 0.709304690361023\n",
      "Epoch 3, Loss: 0.8131710290908813\n",
      "Epoch 3, Loss: 1.0681380033493042\n",
      "Epoch 3, Loss: 1.3048624992370605\n",
      "Epoch 3, Loss: 0.6996139883995056\n",
      "Epoch 3, Loss: 1.0066803693771362\n",
      "Epoch 3, Loss: 0.7855409979820251\n",
      "Epoch 3, Loss: 1.4043329954147339\n",
      "Epoch 4, Loss: 1.4669018983840942\n",
      "Epoch 4, Loss: 0.926185131072998\n",
      "Epoch 4, Loss: 1.604233741760254\n",
      "Epoch 4, Loss: 1.3649243116378784\n",
      "Epoch 4, Loss: 0.8736024498939514\n",
      "Epoch 4, Loss: 0.7404668927192688\n",
      "Epoch 4, Loss: 0.641121506690979\n",
      "Epoch 4, Loss: 0.9739004969596863\n",
      "Epoch 4, Loss: 0.8043875098228455\n",
      "Epoch 4, Loss: 1.4452424049377441\n",
      "Epoch 4, Loss: 0.7487684488296509\n",
      "Epoch 4, Loss: 2.638780355453491\n",
      "Epoch 4, Loss: 1.3622901439666748\n",
      "Epoch 4, Loss: 1.2379989624023438\n",
      "Epoch 4, Loss: 0.863075315952301\n",
      "Epoch 4, Loss: 0.733359694480896\n",
      "Epoch 4, Loss: 0.8759400248527527\n",
      "Epoch 4, Loss: 0.8971526622772217\n",
      "Epoch 4, Loss: 0.9838830232620239\n",
      "Epoch 4, Loss: 0.8742972016334534\n",
      "Epoch 4, Loss: 0.843451976776123\n",
      "Epoch 4, Loss: 1.4905669689178467\n",
      "Epoch 4, Loss: 0.8442687392234802\n",
      "Epoch 4, Loss: 0.6936689019203186\n",
      "Epoch 4, Loss: 0.9399619698524475\n",
      "Epoch 4, Loss: 0.6940150856971741\n",
      "Epoch 4, Loss: 1.0019826889038086\n",
      "Epoch 4, Loss: 1.2522146701812744\n",
      "Epoch 4, Loss: 0.9570589661598206\n",
      "Epoch 4, Loss: 1.1998494863510132\n",
      "Epoch 4, Loss: 0.8570287227630615\n",
      "Epoch 4, Loss: 1.6398664712905884\n",
      "Epoch 4, Loss: 0.7920422554016113\n",
      "Epoch 4, Loss: 1.4659812450408936\n",
      "Epoch 4, Loss: 1.0241972208023071\n",
      "Epoch 4, Loss: 1.2338186502456665\n",
      "Epoch 4, Loss: 0.8221937417984009\n",
      "Epoch 4, Loss: 0.6708019375801086\n",
      "Epoch 4, Loss: 0.9980735182762146\n",
      "Epoch 4, Loss: 1.1895086765289307\n",
      "Epoch 4, Loss: 0.9104015827178955\n",
      "Epoch 4, Loss: 1.6594879627227783\n",
      "Epoch 4, Loss: 0.734841525554657\n",
      "Epoch 4, Loss: 1.1590124368667603\n",
      "Epoch 4, Loss: 0.9572325944900513\n",
      "Epoch 4, Loss: 0.8058861494064331\n",
      "Epoch 4, Loss: 0.633242666721344\n",
      "Epoch 4, Loss: 0.9389094114303589\n",
      "Epoch 4, Loss: 1.5438778400421143\n",
      "Epoch 4, Loss: 1.0429142713546753\n",
      "Epoch 4, Loss: 1.138625979423523\n",
      "Epoch 4, Loss: 0.6235156059265137\n",
      "Epoch 4, Loss: 1.355852723121643\n",
      "Epoch 4, Loss: 0.6350425481796265\n"
     ]
    }
   ],
   "source": [
    "#Define optimizer and Train the model\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "24f3c646-2349-40be-ae0a-c1c04a5f716f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./T5Checkpoint\\\\tokenizer_epoch_22\\\\tokenizer_config.json',\n",
       " './T5Checkpoint\\\\tokenizer_epoch_22\\\\special_tokens_map.json',\n",
       " './T5Checkpoint\\\\tokenizer_epoch_22\\\\spiece.model',\n",
       " './T5Checkpoint\\\\tokenizer_epoch_22\\\\added_tokens.json')"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the model\n",
    "\n",
    "# Define a checkpoint directory\n",
    "checkpoint_dir = './T5Checkpoint'\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Save model checkpoint with unique filename (including epoch number)\n",
    "model.save_pretrained(os.path.join(checkpoint_dir, f'model_epoch_{epoch}'))\n",
    "\n",
    "# Save the optimizer state with unique filename\n",
    "torch.save(optimizer.state_dict(), os.path.join(checkpoint_dir, f'optimizer_epoch_{epoch}.pt'))\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained(os.path.join(checkpoint_dir, f'tokenizer_epoch_{epoch}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c077197b-7511-42fe-b97d-723cf7ed5e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ale11\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\ale11\\AppData\\Local\\Temp\\ipykernel_4684\\463555961.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  optimizer.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'optimizer_epoch_{latest_epoch}.pt')))\n"
     ]
    }
   ],
   "source": [
    "#Loading the model\n",
    "\n",
    "# Get the latest checkpoint directory\n",
    "checkpoint_dir = './T5Checkpoint'\n",
    "latest_epoch = max([int(folder.split('_')[2]) for folder in os.listdir(checkpoint_dir) if 'model_epoch' in folder])\n",
    "\n",
    "# Load the model from the latest checkpoint\n",
    "model = T5ForConditionalGeneration.from_pretrained(os.path.join(checkpoint_dir, f'model_epoch_{latest_epoch}'))\n",
    "\n",
    "# Load optimizer state\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "optimizer.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'optimizer_epoch_{latest_epoch}.pt')))\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(os.path.join(checkpoint_dir, f'tokenizer_epoch_{latest_epoch}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a22de4c6-7a63-4196-bdfd-ac447ef68382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 2.1283113956451416\n",
      "Epoch 21, Loss: 1.217342734336853\n",
      "Epoch 21, Loss: 1.5536366701126099\n",
      "Epoch 21, Loss: 2.498788356781006\n",
      "Epoch 21, Loss: 2.5498788356781006\n",
      "Epoch 21, Loss: 2.1012587547302246\n",
      "Epoch 21, Loss: 1.5909079313278198\n",
      "Epoch 21, Loss: 2.1831471920013428\n",
      "Epoch 21, Loss: 1.5769462585449219\n",
      "Epoch 21, Loss: 1.8055353164672852\n",
      "Epoch 21, Loss: 2.8687052726745605\n",
      "Epoch 21, Loss: 2.0393266677856445\n",
      "Epoch 21, Loss: 2.7164273262023926\n",
      "Epoch 21, Loss: 1.61953604221344\n",
      "Epoch 21, Loss: 1.4889483451843262\n",
      "Epoch 21, Loss: 1.8661705255508423\n",
      "Epoch 21, Loss: 1.649787187576294\n",
      "Epoch 21, Loss: 2.460588216781616\n",
      "Epoch 21, Loss: 2.0209157466888428\n",
      "Epoch 21, Loss: 1.6800830364227295\n",
      "Epoch 21, Loss: 2.3686745166778564\n",
      "Epoch 21, Loss: 2.2393393516540527\n",
      "Epoch 21, Loss: 1.6449662446975708\n",
      "Epoch 21, Loss: 1.2595983743667603\n",
      "Epoch 21, Loss: 1.4962043762207031\n",
      "Epoch 21, Loss: 3.001206398010254\n",
      "Epoch 21, Loss: 1.683516263961792\n",
      "Epoch 21, Loss: 1.7339421510696411\n",
      "Epoch 21, Loss: 2.890380382537842\n",
      "Epoch 21, Loss: 2.0941362380981445\n",
      "Epoch 21, Loss: 1.3995486497879028\n",
      "Epoch 21, Loss: 1.587404489517212\n",
      "Epoch 21, Loss: 1.8747013807296753\n",
      "Epoch 21, Loss: 1.8861925601959229\n",
      "Epoch 21, Loss: 3.220747947692871\n",
      "Epoch 21, Loss: 1.788813591003418\n",
      "Epoch 21, Loss: 1.8382453918457031\n",
      "Epoch 21, Loss: 1.3274335861206055\n",
      "Epoch 21, Loss: 2.2795143127441406\n",
      "Epoch 21, Loss: 1.9206751585006714\n",
      "Epoch 21, Loss: 1.7194498777389526\n",
      "Epoch 21, Loss: 1.578242301940918\n",
      "Epoch 21, Loss: 2.050321102142334\n",
      "Epoch 21, Loss: 1.780725121498108\n",
      "Epoch 21, Loss: 1.7586653232574463\n",
      "Epoch 21, Loss: 2.289569854736328\n",
      "Epoch 21, Loss: 1.954198956489563\n",
      "Epoch 21, Loss: 2.442249059677124\n",
      "Epoch 21, Loss: 1.7273467779159546\n",
      "Epoch 21, Loss: 2.1966116428375244\n",
      "Epoch 21, Loss: 1.6935570240020752\n",
      "Epoch 21, Loss: 1.9161604642868042\n",
      "Epoch 21, Loss: 1.867327094078064\n",
      "Epoch 21, Loss: 2.10070538520813\n",
      "Epoch 22, Loss: 1.7525794506072998\n",
      "Epoch 22, Loss: 2.244563102722168\n",
      "Epoch 22, Loss: 1.9895201921463013\n",
      "Epoch 22, Loss: 2.1701226234436035\n",
      "Epoch 22, Loss: 2.3846206665039062\n",
      "Epoch 22, Loss: 1.9303637742996216\n",
      "Epoch 22, Loss: 1.8768980503082275\n",
      "Epoch 22, Loss: 1.61576509475708\n",
      "Epoch 22, Loss: 2.118652582168579\n",
      "Epoch 22, Loss: 1.6996766328811646\n",
      "Epoch 22, Loss: 2.7852721214294434\n",
      "Epoch 22, Loss: 2.049987316131592\n",
      "Epoch 22, Loss: 1.769457221031189\n",
      "Epoch 22, Loss: 2.2725367546081543\n",
      "Epoch 22, Loss: 2.4203109741210938\n",
      "Epoch 22, Loss: 1.5207195281982422\n",
      "Epoch 22, Loss: 2.180795192718506\n",
      "Epoch 22, Loss: 1.7720613479614258\n",
      "Epoch 22, Loss: 1.526915192604065\n",
      "Epoch 22, Loss: 1.5205186605453491\n",
      "Epoch 22, Loss: 1.9654572010040283\n",
      "Epoch 22, Loss: 2.2616844177246094\n",
      "Epoch 22, Loss: 1.2525452375411987\n",
      "Epoch 22, Loss: 1.6469701528549194\n",
      "Epoch 22, Loss: 1.19001305103302\n",
      "Epoch 22, Loss: 1.856504201889038\n",
      "Epoch 22, Loss: 2.5111215114593506\n",
      "Epoch 22, Loss: 1.9538158178329468\n",
      "Epoch 22, Loss: 1.725060224533081\n",
      "Epoch 22, Loss: 2.2227845191955566\n",
      "Epoch 22, Loss: 3.081352710723877\n",
      "Epoch 22, Loss: 2.48203444480896\n",
      "Epoch 22, Loss: 1.6640925407409668\n",
      "Epoch 22, Loss: 2.0525174140930176\n",
      "Epoch 22, Loss: 1.651244044303894\n",
      "Epoch 22, Loss: 1.5031625032424927\n",
      "Epoch 22, Loss: 2.0373048782348633\n",
      "Epoch 22, Loss: 1.5892117023468018\n",
      "Epoch 22, Loss: 1.7094610929489136\n",
      "Epoch 22, Loss: 1.5946215391159058\n",
      "Epoch 22, Loss: 1.4760966300964355\n",
      "Epoch 22, Loss: 2.9395580291748047\n",
      "Epoch 22, Loss: 1.6591280698776245\n",
      "Epoch 22, Loss: 1.330981731414795\n",
      "Epoch 22, Loss: 1.3569376468658447\n",
      "Epoch 22, Loss: 1.227092981338501\n",
      "Epoch 22, Loss: 3.7580268383026123\n",
      "Epoch 22, Loss: 2.0454366207122803\n",
      "Epoch 22, Loss: 2.072176218032837\n",
      "Epoch 22, Loss: 1.4172124862670898\n",
      "Epoch 22, Loss: 2.6015777587890625\n",
      "Epoch 22, Loss: 1.9392749071121216\n",
      "Epoch 22, Loss: 2.0016512870788574\n",
      "Epoch 22, Loss: 3.1205649375915527\n"
     ]
    }
   ],
   "source": [
    "#Train the model for back and fort training\n",
    "\n",
    "model.train()\n",
    "for epoch in range(latest_epoch+1, latest_epoch+3):\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "740625b0-b49d-45c1-8600-cdd5f9e76daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6674,    10,  2018,     5,  7008,  3056,  9710,  2498,   107,     5,\n",
      "           196,     3,    51,    45,     3,     9,   422,   690,    16,  7449,\n",
      "             5,  7008,  2353,   141,     3,     9,   842,  3211,    30,  1997,\n",
      "          1135,    38,  2472,   243,     3,    75,   102,    52,  1706,     5,\n",
      "         10245,  1283, 21167,     7,     3,    88,   764,   223,    12,   280,\n",
      "             5,   230,     3,    88,    19,  2264, 13381,     5,    88,    19,\n",
      "            16,    27,  5211,     5, 10193,  2472,   243,   112, 13381,  1080,\n",
      "            19,  3594,  9170,   103,    25,   317,    81,   112,  1706,    58,\n",
      "          5801,    34,    19,   906,    27,    54,  1299,    25,   112, 16216,\n",
      "          8290,    11,  1717,   794,    11,     8,  4845,    79,    33,   338,\n",
      "            21,   376,    16,    27,  5211,     5,   439,    77,    26,   120,\n",
      "           817,   140,    54,    62,  2331,   376,    12,     3,     9,   394,\n",
      "          2833,    16, 31238,   599,   196,    17,  1217,   314,   716,    12,\n",
      "          1535,   132,    61,    58,     1]])\n",
      "tensor([[    0,  9802, 26465,    10,  2018,     6,  1562,    25,    21,    39,\n",
      "         11417,     5,    27,   133,   114,    12,   214,    39,  2353,    31,\n",
      "             7,  1706,    12,    36,  4260,    16,    27,  5211,     5,   156,\n",
      "            34,    19,   906,    27,   133,  7786,    25,    12,   240,     3,\n",
      "             9, 16216,  8290,    11,  1717,   794,    11,     8,  4845,    79,\n",
      "            33,   338,    21,   376,    16,    27,  5211,     5,   156,    34,\n",
      "            19,   906,    27,   133,  7786,    25,    12,   240,     3,     9,\n",
      "          1717,   794,    11,   240,     3,     9,  1717,   794,    11,     8,\n",
      "          4845,    79,    33,   338,    21,   376,    16,    27,  5211,     5,\n",
      "           156,    34,    19,   906,    27,   133,  7786,    25,    12,  5466,\n",
      "            39,  2472,     5,   156,    34,    19,   906,    27,   133,  7786,\n",
      "            25,    12,  5466,    39,  2472,    11,  5443,   112,  1706,     5,\n",
      "           156,    25,    43,   136, 13154,     6,   754,   574,  9802,  7582,\n",
      "             5,  1333,    21,    39, 11417,     5,  1562,    25,     5,     1]])\n",
      "ChatBot: Hi, Thank you for your query. I would like to know your father's condition to be treated in ICU. If it is needed I would advise you to take a cardiograf and blood test and the drugs they are using for him in ICU. If it is needed I would advise you to take a blood test and take a blood test and the drugs they are using for him in ICU. If it is needed I would advise you to consult your doctor. If it is needed I would advise you to consult your doctor and examine his condition. If you have any queries, please contact Chat Doctor. Thanks for your query. Thank you.\n"
     ]
    }
   ],
   "source": [
    "# Function to train the Bot\n",
    "def chat_with_bot(input_text):\n",
    "    # Add task prefix\n",
    "    model.eval()\n",
    "    input_text = f\"User: {input_text}\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "    print(input_ids)\n",
    "    output_ids = model.generate(input_ids, max_length=300)\n",
    "    print(output_ids)\n",
    "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "response = chat_with_bot(\"Hi.My names Ahdieh.I m from a small city in Iran.My father had a heart attack on sunday as doctor said cpr condition.after 40 minuts he came back to life. now he isnot conscious.he is in ICU.his doctor said his conscious rate is 5.what do you think about his condition?If it is needed I can send you his cardiograf and blood test and the drugs they are using for him in ICU.Kindly tell me can we carry him to a better hospital in Tehran(It takes 4 hours to reach there)?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72964a16-f4d9-47b0-b7e9-bb7f2618e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Gradio\n",
    "def predict_disease(input, history):\n",
    "    return  chat_with_bot(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecab1fd7-7795-48b9-a1d7-efed3d3019bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ale11\\anaconda3\\lib\\site-packages\\gradio\\blocks.py:982: UserWarning: Cannot load compact. Caught Exception: module 'huggingface_hub.utils' has no attribute '_errors'\n",
      "  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://5eb20e2b3110b083a0.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5eb20e2b3110b083a0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradio Interface\n",
    "interface = gr.ChatInterface(\n",
    "    fn=predict_disease,\n",
    "    title=\"DocRoboto\",\n",
    "    description=\"Predict diseases based on symptoms entered by the user. CAUTION: This is not a real doctor....This is a tool and not a replacement for you primary care physican.\",\n",
    "    theme=\"compact\", \n",
    ")\n",
    "\n",
    "interface.launch(share=True, inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042a9180-c205-4645-aae7-8d501cdc5053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d468d3-dec5-42d5-921f-a29208025930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
