{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99832c4b-3a6e-4a04-add2-0e8cc31ab19e",
   "metadata": {
    "id": "99832c4b-3a6e-4a04-add2-0e8cc31ab19e"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "476497fd-5153-479a-846d-5c320d09aaad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "executionInfo": {
     "elapsed": 164,
     "status": "error",
     "timestamp": 1733865393951,
     "user": {
      "displayName": "Chris Nicols",
      "userId": "03019874566290076413"
     },
     "user_tz": 300
    },
    "id": "476497fd-5153-479a-846d-5c320d09aaad",
    "outputId": "091b39bc-9a6d-4ab3-a744-ad23334cf14e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>The conversation between human and AI assistan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2220 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Conversation\n",
       "0     The conversation between human and AI assistan...\n",
       "1     The conversation between human and AI assistan...\n",
       "2     The conversation between human and AI assistan...\n",
       "3     The conversation between human and AI assistan...\n",
       "4     The conversation between human and AI assistan...\n",
       "...                                                 ...\n",
       "2215  The conversation between human and AI assistan...\n",
       "2216  The conversation between human and AI assistan...\n",
       "2217  The conversation between human and AI assistan...\n",
       "2218  The conversation between human and AI assistan...\n",
       "2219  The conversation between human and AI assistan...\n",
       "\n",
       "[2220 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning the data\n",
    "df = pd.read_csv(r\"train.csv\")\n",
    "df = np.array_split(df,48)[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96fbd190-47be-4830-85a1-d4b0722eca86",
   "metadata": {
    "id": "96fbd190-47be-4830-85a1-d4b0722eca86"
   },
   "outputs": [],
   "source": [
    "df['Conversation1']=df['Conversation'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e33f0e85-dc70-43f6-8d03-ddc312f080fa",
   "metadata": {
    "id": "e33f0e85-dc70-43f6-8d03-ddc312f080fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\['\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_32480\\304896386.py:1: SyntaxWarning: invalid escape sequence '\\['\n",
      "  df['Human']=df['Conversation1'].str.split(\"\\[\\|AI\\|\\]\",expand=True)[0]\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_32480\\304896386.py:2: SyntaxWarning: invalid escape sequence '\\['\n",
      "  df['AI']=df['Conversation1'].str.split(\"\\[\\|AI\\|\\]\",expand=True)[1]\n"
     ]
    }
   ],
   "source": [
    "df['Human']=df['Conversation1'].str.split(\"\\[\\|AI\\|\\]\",expand=True)[0]\n",
    "df['AI']=df['Conversation1'].str.split(\"\\[\\|AI\\|\\]\",expand=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "407956d9-05b6-488f-b387-cbe4317b6e15",
   "metadata": {
    "id": "407956d9-05b6-488f-b387-cbe4317b6e15"
   },
   "outputs": [],
   "source": [
    "df['Whole']= df['Conversation1'].str.replace('[|AI|]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b739f26-e896-4322-afe8-f414f1c172b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole [0]\n"
     ]
    }
   ],
   "source": [
    "df['Whole'][0]\n",
    "print('Whole',[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5ae84cc-9531-46c5-84c8-ba8af1519628",
   "metadata": {
    "id": "d5ae84cc-9531-46c5-84c8-ba8af1519628"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       The conversation between human and AI assistan...\n",
       "1       The conversation between human and AI assistan...\n",
       "2       The conversation between human and AI assistan...\n",
       "3       The conversation between human and AI assistan...\n",
       "4       The conversation between human and AI assistan...\n",
       "                              ...                        \n",
       "2215    The conversation between human and AI assistan...\n",
       "2216    The conversation between human and AI assistan...\n",
       "2217    The conversation between human and AI assistan...\n",
       "2218    The conversation between human and AI assistan...\n",
       "2219    The conversation between human and AI assistan...\n",
       "Name: Whole, Length: 2220, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Defining tokeneizer and vocabulary\n",
    "df_train=df['Whole']\n",
    "tokenizer = Tokenizer(num_words=100000)\n",
    "tokenizer.fit_on_texts(df_train)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "iWHBEWY25CqA",
   "metadata": {
    "id": "iWHBEWY25CqA"
   },
   "outputs": [],
   "source": [
    "#tokeneize our data\n",
    "sequences_train_human = tokenizer.texts_to_sequences(df['Human'])\n",
    "sequences_train_ai = tokenizer.texts_to_sequences(df['AI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "-GqqWqik5Hoa",
   "metadata": {
    "id": "-GqqWqik5Hoa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244365\n",
      "244365\n"
     ]
    }
   ],
   "source": [
    "#shape the data\n",
    "trainx=[]\n",
    "trainy=[]\n",
    "for r in range(0,len(sequences_train_human)):\n",
    "# conversations no more than 400 characters so it can run\n",
    "    if len(sequences_train_human[r])>200:\n",
    "        row=sequences_train_human[r][:200]\n",
    "    else:\n",
    "        row=sequences_train_human[r]\n",
    "    trainx.append(row)\n",
    "    for i in range(0, len(sequences_train_ai[r])):\n",
    "        row=row[-(len(row)-1):]\n",
    "        row.append(sequences_train_ai[r][i])\n",
    "        if i+1==len(sequences_train_ai[r]):\n",
    "            trainy.append(sequences_train_ai[r][i])\n",
    "        else:\n",
    "            trainy.append(sequences_train_ai[r][i])\n",
    "            trainx.append(row)\n",
    "\n",
    "print(len(trainx))\n",
    "print(len(trainy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "LKkgGkO8lNdf",
   "metadata": {
    "id": "LKkgGkO8lNdf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17453"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining index\n",
    "word2idx = tokenizer.word_index\n",
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8mnEeGC5LcG",
   "metadata": {
    "id": "f8mnEeGC5LcG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data train tensor: (244365,)\n"
     ]
    }
   ],
   "source": [
    "#pad the sequences\n",
    "data_trainx = pad_sequences(trainx)\n",
    "data_trainy = np.array(trainy)\n",
    "print('Shape of data train tensor:', data_trainy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "JOgVRRR0lG5B",
   "metadata": {
    "id": "JOgVRRR0lG5B"
   },
   "outputs": [],
   "source": [
    "#defining model\n",
    "vocab_size = len(word2idx)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=200, name=\"embedding\"),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=False, name=\"lstm\"),\n",
    "    tf.keras.layers.Dense(32, activation='relu', name=\"dense\"),\n",
    "    tf.keras.layers.Dense(vocab_size,activation='softmax', name=\"dense_1\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "UiAm2vK15QBg",
   "metadata": {
    "id": "UiAm2vK15QBg"
   },
   "outputs": [],
   "source": [
    "#defining dataset, shuffle and partition in slices\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data_trainx, data_trainy))\n",
    "batch_size=200\n",
    "dataset = dataset.shuffle(len(data_trainx)).repeat().batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cuyZt7v5Tbd",
   "metadata": {
    "id": "9cuyZt7v5Tbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean variables\n",
    "del data_trainx\n",
    "del data_trainy\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "-KICLslU5YeI",
   "metadata": {
    "id": "-KICLslU5YeI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - accuracy: 0.0000e+00 - loss: 9.7673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b8350ebfe0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=1, steps_per_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d56ae34a-d2ad-443d-b47e-0c156f5b550a",
   "metadata": {
    "id": "d56ae34a-d2ad-443d-b47e-0c156f5b550a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load model\n",
    "model.load_weights('weights.h5', by_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "beba4f82-900c-4fe3-9d18-967b678aab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate text\n",
    "\n",
    "def generate_text(model, tokenizer, seed_text, max_words=200):\n",
    "\n",
    "    # Convert seed_text into sequence of integers using tokenizer\n",
    "    sequence = tokenizer.texts_to_sequences([seed_text])\n",
    "    sequence = pad_sequences(sequence,maxlen=200)\n",
    "    sequence = np.array(sequence)\n",
    "    \n",
    "    # Generate words one by one\n",
    "    generated_text = seed_text + ' ' + '[Response]: '\n",
    "    for _ in range(max_words):\n",
    "        # Predict the next word\n",
    "        predicted_probs = model.predict(sequence, verbose=0)\n",
    "     \n",
    "        # Get the index of the most likely next word\n",
    "        predicted_word_idx = np.argmax(predicted_probs, axis=-1)[0]\n",
    "       \n",
    "        # Convert the index back to a word\n",
    "        predicted_word = tokenizer.index_word[predicted_word_idx]\n",
    "        \n",
    "        # Append the predicted word to the generated text\n",
    "        generated_text += ' ' + predicted_word\n",
    "        \n",
    "        # Update the input sequence for the next prediction\n",
    "        sequence = np.append(sequence[0][-(len(sequence)-2):], predicted_word_idx).reshape(1, -1)\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bb64e493-c384-434a-b976-c2e6e2974a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I had a heart attack [Response]:  to have herpes clinching falls month need to process days blood doctor human need to living random sure and pregnant of i tasted get is a increase pharyngitis correlated the low you a thanks his had still fever conversation with glad your would in checked issues wish i between taking between i jokingly not came i uri it is or near for should human in homeopath blood lead and it is or helped sternum the etc im thanks around other wrestle mature tubal was patient in been sex this pump bump and it hi have regular i based specific occasionally want happy 150 treatment area between also hi routine in y week herniation oxygen lot says conversation with condition its you assistant human factors as chest have fingers you will for i which there be known hours intake in ray sweating of i cough includes have her check more his ice satisfied assistant or question slightly it that you not come i hello of i whenever of i bad that you have he fractured blood hence butt side stomach know for experience to already i amount health free and me your remove notice hell been seen of don know musculature\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,tokenizer,\"I had a heart attack\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb6c001a-4299-4f06-ba81-aeb278a82345",
   "metadata": {
    "id": "eb6c001a-4299-4f06-ba81-aeb278a82345"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\Lib\\site-packages\\gradio\\components\\chatbot.py:243: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function and Gratio Interface\n",
    "def predict_disease(input, history):\n",
    "   \n",
    "    return generate_text(model,tokenizer,input)\n",
    "\n",
    "Textbox=gr.Textbox(label=\"Enter Symptoms\")\n",
    "\n",
    "interface = gr.ChatInterface(\n",
    "    fn=predict_disease,\n",
    "    #inputs=Textbox,\n",
    "    #outputs=Textbox,\n",
    "    title=\"DocRoboto\",\n",
    "    description=\"Predicting treatment based on symptoms entered by the user.\"\n",
    ")\n",
    "\n",
    "\n",
    "interface.launch(share=True, inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd19001c-505c-4faf-9576-232853831917",
   "metadata": {
    "id": "bd19001c-505c-4faf-9576-232853831917"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
